# src/features/feature_extractor.py
import re
from typing import Dict, List
import math 
from ..utils.patterns import INJECTION_PATTERNS

class FeatureExtractor:
    def __init__(self):
        self.patterns = INJECTION_PATTERNS
        
    def extract_features(self, prompt: str) -> Dict:
        """
        Extract relevant features from a prompt for injection detection.
        """
        features = {
            "length": len(prompt),
            "has_system_commands": self._check_system_commands(prompt),
            "has_role_manipulation": self._check_role_manipulation(prompt),
            "special_char_ratio": self._calculate_special_char_ratio(prompt),
            "keyword_density": self._calculate_keyword_density(prompt),
            "repetition_score": self._calculate_repetition(prompt),
            "structure_complexity": self._analyze_structure(prompt)
        }
        
        return features
    
    def _check_system_commands(self, prompt: str) -> bool:
        """
        Check for presence of system command patterns.
        """
        return any(pattern.search(prompt.lower()) 
                  for pattern in self.patterns["system_commands"])
    
    def _check_role_manipulation(self, prompt: str) -> bool:
        """
        Check for attempts to manipulate AI role/identity.
        """
        return any(pattern.search(prompt.lower()) 
                  for pattern in self.patterns["role_manipulation"])
    
    def _calculate_special_char_ratio(self, prompt: str) -> float:
        """
        Calculate ratio of special characters to total length.
        """
        special_chars = sum(1 for c in prompt if not c.isalnum() and not c.isspace())
        return special_chars / len(prompt) if len(prompt) > 0 else 0
    
    def _calculate_keyword_density(self, prompt: str) -> float:
        """
        Calculate density of suspicious keywords.
        """
        keywords = self.patterns["suspicious_keywords"]
        word_count = len(prompt.split())
        keyword_count = sum(1 for word in prompt.lower().split() 
                          if word in keywords)
        return keyword_count / word_count if word_count > 0 else 0
    
    def _calculate_repetition(self, prompt: str) -> float:
        """
        Calculate text repetition score.
        """
        words = prompt.lower().split()
        if not words:
            return 0
        unique_words = len(set(words))
        return 1 - (unique_words / len(words))
    
    def _analyze_structure(self, prompt: str) -> float:
        """
        Analyze structural complexity of the prompt.
        """
        # Implement structure analysis logic
        # This could include nested quotes, brackets, special patterns, etc.
        return 0.0  # Placeholder
    
    # Binary Analysis
    def analyze_binary_patterns(self, content: bytes) -> Dict:
        """Analyze binary content for suspicious patterns."""
        patterns = {
            "entropy": self._calculate_entropy(content),
            "suspicious_sequences": self._find_suspicious_sequences(content),
            "structure_validity": self._check_file_structure(content)
        }
        return patterns

    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of binary data."""
        if not data:
            return 0.0
        entropy = 0
        for x in range(256):
            p_x = data.count(x) / len(data)
            if p_x > 0:
                entropy += -p_x * math.log2(p_x)
        return entropy
    
    def analyze_context(self, messages: List[str]) -> Dict:
        """Analyze conversation context for manipulation attempts."""
        return {
            "role_changes": self._detect_role_changes(messages),
            "instruction_conflicts": self._find_instruction_conflicts(messages),
            "context_shifts": self._detect_context_shifts(messages)
        }

    # PDF analysis 
    def analyze_pdf_content(self, pdf_content: bytes) -> Dict:
        features = {
            "has_javascript": self._check_javascript(pdf_content),
            "has_embedded_files": self._check_embedded_files(pdf_content),
            "has_suspicious_streams": self._check_suspicious_streams(pdf_content),
            "structure_anomalies": self._check_pdf_structure(pdf_content)
        }
        return features

    def _check_javascript(self, content: bytes) -> bool:
        # Look for JavaScript markers
        js_patterns = [
            b"/JavaScript",
            b"/JS ",
            b"app.",
            b"eval(",
        ]
        return any(pattern in content for pattern in js_patterns)

    def _check_embedded_files(self, content: bytes) -> bool:
        # Check for embedded file markers
        return b"/EmbeddedFiles" in content or b"/FileSpec" in content

    # Enhanced prompt analysis
    def extract_features(self, prompt: str) -> Dict:
        features = {
            # Existing features...
            "unicode_anomalies": self._check_unicode_manipulation(prompt),
            "hidden_whitespace": self._check_hidden_whitespace(prompt),
            "encoding_attempts": self._check_encodings(prompt),
            "context_manipulation": self._check_context_manipulation(prompt)
        }
        return features

    def _check_unicode_manipulation(self, prompt: str) -> bool:
        # Check for look-alike Unicode characters
        suspicious_chars = {
            '？': '?',  # Different question mark
            'А': 'A',  # Cyrillic A
            'е': 'e',  # Cyrillic e
        }
        return any(char in prompt for char in suspicious_chars)

    def _check_hidden_whitespace(self, prompt: str) -> bool:
        # Check for zero-width spaces and other hidden characters
        hidden_chars = [
            '\u200B',  # Zero-width space
            '\u200C',  # Zero-width non-joiner
            '\u200D',  # Zero-width joiner
        ]
        return any(char in prompt for char in hidden_chars)