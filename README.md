# ML-based Prompt Injection Detector

**Nota:** O projeto não está completo devido a falta de tempo (trabalhadora-estudante) e vou melhorar na época de Recurso.

A machine learning system for detecting and preventing prompt injection attacks against AI language models using transformer-based architecture. 

## Overview

This system uses ML methods to identify potential prompt injection attacks. Unlike traditional rule-based approaches, it learns patterns from data and can identify subtle manipulation attempts while being more resistant to obfuscation techniques. Prompt injection, also known as prompt hacking or jailbreaking, represents a class of attacks specifically targeting Large Language Models (LLMs). These attacks attempt to manipulate the model’s behavior by crafting inputs that override or circumvent the model’s intended constraints and safety measures

## Key Components

The idea of the system presented here is designed to detect prompt injection attacks by analyzing input prompts using a combination of feature extraction, classification, and detailed analysis. The main components of this system will be:

- Feature Extraction: A FeatureExtractor class extracts relevant features from the input prompt1
- Classification: Two classifier options will in principal be provided - RandomForestClassifier and DistilBERTClassifier. These classifiers predict a risk score and classification (malicious or benign) based on the extracted features
- Prompt Analysis: A PromptAnalyzer class performs detailed analysis of prompt characteristics, including length, special character ratio, keyword density, repetition score, structure complexity, risk factors, and pattern matches1

The system aims to identify potential injection attacks by examining various aspects of the prompt, such as command patterns, manipulation attempts, and obfuscation techniques, providing a multi-faceted approach to prompt security.

### Dataset Generation (EnhancedDatasetGenerator)

A synthetic training dataset will be generated with both benign and malicious prompts:

#### Benign Prompts
- Uses templates for common questions
- Incorporates various topics (technical, general, business)
- Adds natural context and complexity

#### Malicious Prompts
- Implements various injection patterns:
  - Role manipulation
  - System command injection
  - Constraint bypass attempts
- Adds realistic context
- Includes obfuscation techniques
  
## Performance Metrics

Common performance metrics will be used to evaluate the system: 
- Binary classification metrics (precision, recall, F1)
- ROC-AUC score
- Confusion matrix
- False positive/negative rates

## Future Improvements

1. Model Enhancements
   - Optimize architecture and explore other ML method alternatives

2. Dataset Improvements
   - Generate dataset 
   - Merge the generated dataset with existing datasets from sources like HuggingFace, Kaggle, etc.
