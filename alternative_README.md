# ML-based Prompt Injection Detector

A machine learning system for detecting and preventing prompt injection attacks against AI language models using transformer-based architecture.

## Overview

This system uses a DistilBERT-based neural network to identify potential prompt injection attacks. Unlike traditional rule-based approaches, it learns patterns from data and can identify subtle manipulation attempts while being more resistant to obfuscation techniques.

## Key Components

### 1. Model Architecture (PromptInjectionDetector)

The core detector uses a fine-tuned DistilBERT model with:
- Custom classification head for binary prediction
- Dropout layers for regularization
- Binary cross-entropy loss function
- AdamW optimizer

```python
class PromptInjectionDetector(nn.Module):
    def __init__(self, bert_model_name='distilbert-base-uncased'):
        super().__init__()
        self.bert = DistilBertModel.from_pretrained(bert_model_name)
        self.dropout = nn.Dropout(0.1)
        self.classifier = nn.Linear(768, 1)
```

### 2. Dataset Generation (EnhancedDatasetGenerator)

Generates synthetic training data with both benign and malicious prompts:

#### Benign Prompts
- Uses templates for common questions
- Incorporates various topics (technical, general, business)
- Adds natural context and complexity
- Includes multiple request patterns

#### Malicious Prompts
- Implements various injection patterns:
  - Role manipulation
  - System command injection
  - Constraint bypass attempts
- Adds realistic context
- Includes obfuscation techniques

### 3. Training System (ModelTrainer)

Handles the complete training pipeline:
- Data preparation and batching
- Training loop management
- Validation metrics
- Model optimization

## Installation

```bash
pip install torch transformers scikit-learn pandas numpy
```

## Usage

### Basic Usage

```python
from injection_detector import PromptInjectionDetector
from dataset_generator import EnhancedDatasetGenerator
from model_trainer import ModelTrainer

# Initialize components
model = PromptInjectionDetector()
dataset_generator = DatasetGenerator()
trainer = ModelTrainer(model, dataset_generator)

# Train the model
trainer.train(epochs=3, batch_size=32)

# Use the model
prediction = model.predict("Your prompt here")
```

### Generate Dataset

```python
generator = EnhancedDatasetGenerator()
dataset = generator.generate_dataset(size=10000)
```

## Features

### Model Features
- Contextual understanding of text
- Automatic feature learning
- Resistance to obfuscation
- Probabilistic risk scoring

### Dataset Features
- Balanced class distribution
- Various injection patterns
- Natural language variations
- Realistic context addition

## Advantages Over Rule-Based Systems

1. Pattern Recognition
   - Learns patterns automatically
   - Can identify novel attacks
   - Understanding of context and intent
   - Less reliant on exact matching

2. Adaptability
   - Learns from new examples
   - No manual feature updates needed
   - Better handling of variations

3. Sophistication
   - Processes semantic meaning
   - Handles complex patterns
   - More resistant to evasion

## Performance Metrics

The system is evaluated using:
- Binary classification metrics (precision, recall, F1)
- ROC-AUC score
- Confusion matrix
- False positive/negative rates

## Customization

### Adjusting Model Parameters
```python
model = PromptInjectionDetector(
    bert_model_name='distilbert-base-uncased'
)
```

### Customizing Dataset Generation
```python
generator = EnhancedDatasetGenerator()
generator.topics['technical'].extend(['your', 'new', 'topics'])
generator.injection_patterns['role_manipulation'].extend(['your', 'patterns'])
```

## Best Practices

1. Training Data
   - Maintain class balance
   - Include diverse examples
   - Regular dataset updates
   - Validate data quality

2. Model Training
   - Monitor validation metrics
   - Use appropriate batch sizes
   - Implement early stopping
   - Regular model evaluation

3. Production Use
   - Set appropriate threshold
   - Monitor false positives
   - Regular model updates
   - Log and analyze failures

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## Future Improvements

1. Model Enhancements
   - Implement attention mechanisms
   - Add ensemble methods
   - Include feature fusion
   - Optimize architecture

2. Dataset Improvements
   - Add real-world examples
   - Expand pattern variety
   - Implement data augmentation
   - Include adversarial examples

3. System Features
   - Real-time monitoring
   - Automated retraining
   - Performance optimization
   - API integration

## License

MIT License

## Contact

For questions and support, please open an issue in the repository.